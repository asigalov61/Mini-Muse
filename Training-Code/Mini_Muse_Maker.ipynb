{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "ac5a4cf0-d9d2-47b5-9633-b53f8d99a4d2",
          "kernelId": ""
        },
        "id": "SiTIpPjArIyr"
      },
      "source": [
        "# Mini Muse Maker (ver. 1.0)\n",
        "\n",
        "***\n",
        "\n",
        "Powered by tegridy-tools: https://github.com/asigalov61/tegridy-tools\n",
        "\n",
        "***\n",
        "\n",
        "Credit for GPT2-RGA code used in this colab goes out @ Sashmark97 https://github.com/Sashmark97/midigen and @ Damon Gwinn https://github.com/gwinndr/MusicTransformer-Pytorch\n",
        "\n",
        "***\n",
        "\n",
        "WARNING: This complete implementation is a functioning model of the Artificial Intelligence. Please excercise great humility, care, and respect. https://www.nscai.gov/\n",
        "\n",
        "***\n",
        "\n",
        "#### Project Los Angeles\n",
        "\n",
        "#### Tegridy Code 2022\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "fa0a611c-1803-42ae-bdf6-a49b5a4e781b",
          "kernelId": ""
        },
        "id": "gOd93yV0sGd2"
      },
      "source": [
        "# (Setup Environment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "39411b40-9e39-416e-8fe4-d40f733e7956",
          "kernelId": ""
        },
        "id": "lw-4aqV3sKQG"
      },
      "outputs": [],
      "source": [
        "#@title nvidia-smi gpu check\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "a1a45a91-d909-4fd4-b67a-5e16b971d179",
          "kernelId": ""
        },
        "id": "fX12Yquyuihc"
      },
      "outputs": [],
      "source": [
        "#@title Install all dependencies (run only once per session)\n",
        "\n",
        "!git clone https://github.com/asigalov61/Mini-Muse\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "b8207b76-9514-4c07-95db-95a4742e52c5",
          "kernelId": ""
        },
        "id": "z7n9vnKmug1J"
      },
      "outputs": [],
      "source": [
        "#@title Import all needed modules\n",
        "\n",
        "print('Loading needed modules. Please wait...')\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import secrets\n",
        "\n",
        "if not os.path.exists('/content/Dataset'):\n",
        "    os.makedirs('/content/Dataset')\n",
        "\n",
        "print('Loading TMIDIX and GPT2RGAX modules...')\n",
        "os.chdir('/content/Mini-Muse')\n",
        "import TMIDIX\n",
        "from GPT2RGAX import *\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "os.chdir('/content/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false,
          "id": "20b8698a-0b4e-4fdb-ae49-24d063782e77",
          "kernelId": ""
        },
        "id": "ObPxlEutsQBj"
      },
      "source": [
        "# (FROM SCRATCH) Download and process MIDI dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "editing": false,
          "id": "ffbb7a2a-d91a-477f-ac89-56d77d6cdf42",
          "kernelId": ""
        },
        "id": "snIZ3xKPsPgB"
      },
      "outputs": [],
      "source": [
        "#@title Download original LAKH MIDI Dataset (Recommended)\n",
        "\n",
        "%cd /content/Dataset/\n",
        "\n",
        "!wget 'http://hog.ee.columbia.edu/craffel/lmd/lmd_full.tar.gz'\n",
        "!tar -xvf 'lmd_full.tar.gz'\n",
        "!rm 'lmd_full.tar.gz'\n",
        "\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (PROCESS)"
      ],
      "metadata": {
        "id": "JwrqQeie08t0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "id": "ed07b44f-07fe-45fb-a64f-adba8df1bdcb",
          "kernelId": ""
        },
        "id": "on7sgKEP3Yc8"
      },
      "outputs": [],
      "source": [
        "#@title Process MIDIs with TMIDIX MIDI processor\n",
        "\n",
        "sorted_or_random_file_loading_order = False # Sorted order is NOT usually recommended\n",
        "dataset_ratio = 1 # Change this if you need more data\n",
        "\n",
        "\n",
        "print('TMIDIX MIDI Processor')\n",
        "print('Starting up...')\n",
        "###########\n",
        "\n",
        "files_count = 0\n",
        "\n",
        "gfiles = []\n",
        "\n",
        "melody_chords_f = []\n",
        "\n",
        "###########\n",
        "\n",
        "print('Loading MIDI files...')\n",
        "print('This may take a while on a large dataset in particular.')\n",
        "\n",
        "dataset_addr = \"/content/Dataset\"\n",
        "# os.chdir(dataset_addr)\n",
        "filez = list()\n",
        "for (dirpath, dirnames, filenames) in os.walk(dataset_addr):\n",
        "    filez += [os.path.join(dirpath, file) for file in filenames]\n",
        "print('=' * 70)\n",
        "\n",
        "if filez == []:\n",
        "    print('Could not find any MIDI files. Please check Dataset dir...')\n",
        "    print('=' * 70)\n",
        "\n",
        "if sorted_or_random_file_loading_order:\n",
        "    print('Sorting files...')\n",
        "    filez.sort()\n",
        "    print('Done!')\n",
        "    print('=' * 70)\n",
        "else:\n",
        "    print('Randomizing file list...')\n",
        "    random.shuffle(filez)\n",
        "\n",
        "    \n",
        "stats = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "middles_stats = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "print('Processing MIDI files. Please wait...')\n",
        "for f in tqdm(filez[:int(len(filez) * dataset_ratio)]):\n",
        "    try:\n",
        "        fn = os.path.basename(f)\n",
        "        fn1 = fn.split('.')[0]\n",
        "\n",
        "        #print('Loading MIDI file...')\n",
        "        score = TMIDIX.midi2ms_score(open(f, 'rb').read())\n",
        "\n",
        "        events_matrix = []\n",
        "\n",
        "        itrack = 1\n",
        "\n",
        "        patches = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "        patch_map = [[0, 1, 2, 3, 4, 5, 6, 7], # Piano \n",
        "                     [24, 25, 26, 27, 28, 29, 30], # Guitar\n",
        "                     [32, 33, 34, 35, 36, 37, 38, 39], # Bass\n",
        "                     [40, 41], # Violin\n",
        "                     [42, 43], # Cello\n",
        "                     [46], # Harp\n",
        "                     [56, 57, 58, 59, 60], # Trumpet\n",
        "                     [71, 72], # Clarinet\n",
        "                     [73, 74, 75], # Flute\n",
        "                     [-1], # Fake Drums\n",
        "                     [52, 53] # Choir\n",
        "                    ]\n",
        "\n",
        "        while itrack < len(score):\n",
        "            for event in score[itrack]:         \n",
        "                if event[0] == 'note' or event[0] == 'patch_change':\n",
        "                    events_matrix.append(event)\n",
        "            itrack += 1\n",
        "\n",
        "        if len(events_matrix) > 512:\n",
        "\n",
        "          events_matrix.sort(key=lambda x: x[1])\n",
        "\n",
        "          events_matrix1 = []\n",
        "          for event in events_matrix:\n",
        "                  if event[0] == 'patch_change':\n",
        "                      patches[event[2]] = event[3]\n",
        "\n",
        "                  if event[0] == 'note':\n",
        "                      event.extend([patches[event[3]]])\n",
        "                      once = False\n",
        "                      \n",
        "                      for p in patch_map:\n",
        "                          if event[6] in p and event[3] != 9: # Except the drums\n",
        "                              event[3] = patch_map.index(p)\n",
        "                              once = True\n",
        "                              \n",
        "                      if not once and event[3] != 9: # Except the drums\n",
        "                          event[3] = 0 # All other instruments/patches channel\n",
        "                          event[5] = max(80, event[5])\n",
        "                          \n",
        "                      if event[3] < 11: # We won't write chans 11-16 for now...\n",
        "                          events_matrix1.append(event)\n",
        "                          stats[event[3]] += 1\n",
        "\n",
        "          # Sorting...\n",
        "          events_matrix1.sort(key=lambda x: (x[1], x[3]))\n",
        "\n",
        "          # recalculating timings\n",
        "          for e in events_matrix1:\n",
        "              e[1] = int(e[1] / 16)\n",
        "              e[2] = int(e[2] / 32)\n",
        "          \n",
        "          # final processing...\n",
        "\n",
        "          if len(events_matrix1) > 512:\n",
        "              melody_chords = []\n",
        "\n",
        "              pe = events_matrix1[int(len(events_matrix1) / 2)-128]\n",
        "              for e in events_matrix1[int(len(events_matrix1) / 2)-128:int(len(events_matrix1) / 2)+128]:\n",
        "\n",
        "                  time = max(0, min(127, e[1]-pe[1]))\n",
        "                  dur = max(1, min(127, e[2]))\n",
        "                  cha = max(0, min(10, e[3]))\n",
        "                  ptc = max(1, min(127, e[4]))\n",
        "                  vel = max(16, min(127, e[5]))\n",
        "\n",
        "                  div_vel = int(vel / 16)\n",
        "\n",
        "                  chan_vel = (cha * 10) + div_vel\n",
        "\n",
        "                  melody_chords.append([chan_vel, time+128, dur+256, ptc+384])\n",
        "\n",
        "                  middles_stats[cha] += 1\n",
        "\n",
        "                  pe = e\n",
        "\n",
        "              melody_chords_f.append(melody_chords)\n",
        "\n",
        "              files_count += 1\n",
        "        \n",
        "    except KeyboardInterrupt:\n",
        "        print('Saving current progress and quitting...')\n",
        "        break  \n",
        "\n",
        "    except:\n",
        "        print('Bad MIDI:', f)\n",
        "        continue\n",
        "\n",
        "print('=' * 70)\n",
        "        \n",
        "print('Done!')   \n",
        "print('=' * 70)\n",
        "\n",
        "print('Resulting Stats:')\n",
        "print('=' * 70)\n",
        "print('Total MIDI Excerpts:', files_count)\n",
        "print('=' * 70)\n",
        "\n",
        "print('Piano:', middles_stats[0])\n",
        "print('Guitar:', middles_stats[1])\n",
        "print('Bass:', middles_stats[2])\n",
        "print('Violin:', middles_stats[3])\n",
        "print('Cello:', middles_stats[4])\n",
        "print('Harp:', middles_stats[5])\n",
        "print('Trumpet:', middles_stats[6])\n",
        "print('Clarinet:', middles_stats[7])\n",
        "print('Flute:', middles_stats[8])\n",
        "print('Drums:', middles_stats[9])\n",
        "print('Choir:', middles_stats[10])\n",
        "\n",
        "print('=' * 70)\n",
        "\n",
        "TMIDIX.Tegridy_Any_Pickle_File_Writer(melody_chords_f, '/content/Mini_Muse_Processed_MIDIs')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (PREP INTs)"
      ],
      "metadata": {
        "id": "O9iACjm42uTz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "0826f622-2edc-4f09-9a01-58df049738d4",
          "kernelId": ""
        },
        "id": "t-jV34sBHX9z",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Process and prep INTs...\n",
        "\n",
        "\n",
        "randomize_dataset = True\n",
        "\n",
        "print('=' * 70)\n",
        "print('Prepping INTs dataset...')\n",
        "\n",
        "if randomize_dataset:\n",
        "    print('=' * 70)\n",
        "    print('Randomizing the dataset...')\n",
        "    random.shuffle(melody_chords_f)\n",
        "    print('Done!')\n",
        "    \n",
        "print('=' * 70)\n",
        "print('Processing the dataset...')\n",
        "\n",
        "train_data1 = []\n",
        "\n",
        "for m in tqdm(melody_chords_f):\n",
        "  if len(m) != 256:\n",
        "    print('Error')\n",
        "  else:\n",
        "    train_data1.extend([0])\n",
        "    for mm in m:\n",
        "      train_data1.extend(mm)\n",
        "\n",
        "print('Done!')        \n",
        "print('=' * 70)\n",
        "        \n",
        "print('Total INTs:', len(train_data1))\n",
        "print('Minimum INT:', min(train_data1))\n",
        "print('Maximum INT:', max(train_data1))\n",
        "print('Unique INTs:', len(set(train_data1)))\n",
        "print('Intro/Zero INTs:', train_data1.count(0))\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save INTs\n",
        "TMIDIX.Tegridy_Any_Pickle_File_Writer(train_data1, '/content/Mini_Muse_INTs')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uiw3tUA63kUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ye9rNzOHX90"
      },
      "source": [
        "# Test the resulting INTs dataset..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Test INTs\n",
        "print('Sample INTs', train_data1[:15])\n",
        "\n",
        "out = train_data1[:16000]\n",
        "\n",
        "if len(out) != 0:\n",
        "    \n",
        "    song = out\n",
        "    song_f = []\n",
        "    time = 0\n",
        "    dur = 0\n",
        "    vel = 0\n",
        "    pitch = 0\n",
        "    channel = 0\n",
        "\n",
        "    son = []\n",
        "\n",
        "    song1 = []\n",
        "\n",
        "    for s in song:\n",
        "      if s > 127:\n",
        "        son.append(s)\n",
        "\n",
        "      else:\n",
        "        if len(son) == 4:\n",
        "          song1.append(son)\n",
        "        son = []\n",
        "        son.append(s)\n",
        "    \n",
        "    for s in song1:\n",
        "\n",
        "        channel = s[0] // 10\n",
        "\n",
        "        vel = (s[0] % 10) * 16\n",
        "\n",
        "        time += (s[1]-128) * 16\n",
        "            \n",
        "        dur = (s[2] - 256) * 32\n",
        "        \n",
        "        pitch = (s[3] - 384)\n",
        "                                  \n",
        "        song_f.append(['note', time, dur, channel, pitch, vel ])\n",
        "\n",
        "    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
        "                                                        output_signature = 'Mini Muse',  \n",
        "                                                        output_file_name = '/content/Mini-Muse-Music-Composition', \n",
        "                                                        track_name='Project Los Angeles',\n",
        "                                                        list_of_MIDI_patches=[0, 24, 32, 40, 42, 46, 56, 71, 73, 0, 53, 0, 0, 0, 0, 0],\n",
        "                                                        number_of_ticks_per_quarter=500)\n",
        "\n",
        "    print('Done!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zppMJ8gA3L4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (LOAD INTs)"
      ],
      "metadata": {
        "id": "eMrq1osy3_ZG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "id": "53252e52-5e68-4e60-8e4d-a584667749a4",
          "kernelId": ""
        },
        "id": "lT0TyqUnpxu_"
      },
      "outputs": [],
      "source": [
        "#@title Load processed INTs dataset\n",
        "\n",
        "SEQ_LEN = max_seq\n",
        "\n",
        "BATCH_SIZE = 4 # Change this to your specs\n",
        "\n",
        "# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n",
        "\n",
        "print('=' * 50)\n",
        "print('Loading training data...')\n",
        "\n",
        "data_train, data_val = torch.LongTensor(train_data1), torch.LongTensor(train_data1)\n",
        "\n",
        "class MusicSamplerDataset(Dataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        rand = secrets.randbelow((self.data.size(0)-(self.seq_len+1)) // (self.seq_len+1)) * (self.seq_len+1)\n",
        "\n",
        "        x = self.data[rand: rand + self.seq_len].long()\n",
        "        trg = self.data[(rand+1): (rand+1) + self.seq_len].long()\n",
        "        \n",
        "        return x, trg\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0)\n",
        "\n",
        "train_dataset = MusicSamplerDataset(data_train, SEQ_LEN)\n",
        "val_dataset   = MusicSamplerDataset(data_val, SEQ_LEN)\n",
        "train_loader  = DataLoader(train_dataset, batch_size = BATCH_SIZE)\n",
        "val_loader    = DataLoader(val_dataset, batch_size = BATCH_SIZE)\n",
        "print('=' * 50)\n",
        "print('Total INTs in the dataset', len(train_data1))\n",
        "print('Total unique INTs in the dataset', len(set(train_data1)))\n",
        "print('Max INT in the dataset', max(train_data1))\n",
        "print('Min INT in the dataset', min(train_data1))\n",
        "print('=' * 50)\n",
        "print('Length of the dataset:',len(train_dataset))\n",
        "print('Number of batched samples per epoch:', len(train_data1) // max_seq // BATCH_SIZE)\n",
        "print('=' * 50)\n",
        "print('Sample train dataset:', train_dataset[0])\n",
        "print('Sample val dataset:', val_dataset[0])\n",
        "print('=' * 50)\n",
        "print('Train loader length:', len(train_loader))\n",
        "print('Val loader length:', len(val_loader))\n",
        "print('=' * 50)\n",
        "print('Done! Enjoy! :)')\n",
        "print('=' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkVqviDzJOrv"
      },
      "source": [
        "# (TRAIN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9CBW8xYupH8"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "4aa21407-a3e9-4ed2-9bf1-83c295482b8a",
          "kernelId": ""
        },
        "id": "2moo7uUmpxvC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Train\n",
        "\n",
        "DIC_SIZE = 512\n",
        "\n",
        "# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n",
        "\n",
        "config = GPTConfig(DIC_SIZE, \n",
        "                   max_seq,\n",
        "                   dim_feedforward=1024,\n",
        "                   n_layer=16, \n",
        "                   n_head=16, \n",
        "                   n_embd=1024,\n",
        "                   enable_rpr=True,\n",
        "                   er_len=max_seq)\n",
        "\n",
        "# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = GPT(config)\n",
        "\n",
        "model = nn.DataParallel(model)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "#=====\n",
        "\n",
        "init_step = 0\n",
        "lr = LR_DEFAULT_START\n",
        "lr_stepper = LrStepTracker(d_model, SCHEDULER_WARMUP_STEPS, init_step)\n",
        "eval_loss_func = nn.CrossEntropyLoss(ignore_index=DIC_SIZE)\n",
        "train_loss_func = eval_loss_func\n",
        "\n",
        "opt = Adam(model.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)\n",
        "lr_scheduler = LambdaLR(opt, lr_stepper.step)\n",
        "\n",
        "\n",
        "#===\n",
        "\n",
        "best_eval_acc        = 0.0\n",
        "best_eval_acc_epoch  = -1\n",
        "best_eval_loss       = float(\"inf\")\n",
        "best_eval_loss_epoch = -1\n",
        "best_acc_file = '/content/gpt2_rpr_acc.pth'\n",
        "best_loss_file = '/content/gpt2_rpr_loss.pth'\n",
        "loss_train, loss_val, acc_val = [], [], []\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "    new_best = False\n",
        "    \n",
        "    loss = train(epoch+1, \n",
        "                 model, train_loader, \n",
        "                 train_loss_func, \n",
        "                 opt, \n",
        "                 lr_scheduler, \n",
        "                 num_iters=-1, \n",
        "                 save_checkpoint_steps=4000)\n",
        "    \n",
        "    loss_train.append(loss)\n",
        "    \n",
        "    eval_loss, eval_acc = eval_model(model, val_loader, eval_loss_func, num_iters=-1)\n",
        "    loss_val.append(eval_loss)\n",
        "    acc_val.append(eval_acc)\n",
        "    \n",
        "    if(eval_acc > best_eval_acc):\n",
        "        best_eval_acc = eval_acc\n",
        "        best_eval_acc_epoch  = epoch+1\n",
        "        torch.save(model.state_dict(), best_acc_file)\n",
        "        new_best = True\n",
        "\n",
        "    if(eval_loss < best_eval_loss):\n",
        "        best_eval_loss       = eval_loss\n",
        "        best_eval_loss_epoch = epoch+1\n",
        "        torch.save(model.state_dict(), best_loss_file)\n",
        "        new_best = True\n",
        "    \n",
        "    if(new_best):\n",
        "        print(\"Best eval acc epoch:\", best_eval_acc_epoch)\n",
        "        print(\"Best eval acc:\", best_eval_acc)\n",
        "        print(\"\")\n",
        "        print(\"Best eval loss epoch:\", best_eval_loss_epoch)\n",
        "        print(\"Best eval loss:\", best_eval_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gradient": {
          "id": "72338f3f-34c4-40e3-a48a-42ed9729466a",
          "kernelId": ""
        },
        "id": "R4LIXk1vHX92",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Eval funct to eval separately if needed\n",
        "\n",
        "\n",
        "#=====\n",
        "\n",
        "init_step = 0\n",
        "lr = LR_DEFAULT_START\n",
        "lr_stepper = LrStepTracker(d_model, SCHEDULER_WARMUP_STEPS, init_step)\n",
        "eval_loss_func = nn.CrossEntropyLoss(ignore_index=DIC_SIZE)\n",
        "train_loss_func = eval_loss_func\n",
        "\n",
        "opt = Adam(model.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)\n",
        "lr_scheduler = LambdaLR(opt, lr_stepper.step)\n",
        "\n",
        "\n",
        "eval_loss, eval_acc = eval_model(model, val_loader, eval_loss_func, num_iters=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdKFoeke9L7H"
      },
      "source": [
        "# (SAVE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "gradient": {
          "id": "73bea62d-084b-4f9a-9e55-2b34a932a7a4",
          "kernelId": ""
        },
        "id": "gqyDatHC9X1z"
      },
      "outputs": [],
      "source": [
        "#@title Save the model\n",
        "\n",
        "print('Saving the model...')\n",
        "full_path_to_model_checkpoint = \"/content/Mini-Muse-Trained-Model.pth\" #@param {type:\"string\"}\n",
        "torch.save(model.state_dict(), full_path_to_model_checkpoint)\n",
        "print('Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzCMd94Tu_gz"
      },
      "source": [
        "# Congrats! You did it! :)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Mini_Muse_Maker.ipynb",
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}